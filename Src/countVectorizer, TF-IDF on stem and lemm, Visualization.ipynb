{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>newstype</th>\n",
       "      <th>lemm</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>donald trump wish americans happy new year lea...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>donald trump wish american happy new year leav...</td>\n",
       "      <td>donald trump wish american happi new year leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>hous intellig committe chairman devin nune go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>friday  revealed former milwaukee sheriff davi...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>friday  revealed former milwaukee sheriff davi...</td>\n",
       "      <td>friday  reveal former milwauke sheriff david c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>christmas day  donald trump announced would  b...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>christmas day  donald trump announced would  b...</td>\n",
       "      <td>christma day  donald trump announc would  back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>pope francis used annual christmas day message...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>pope francis used annual christmas day message...</td>\n",
       "      <td>pope franci use annual christma day messag reb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>brussels  reuters    nato allies tuesday welco...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>brussels  reuters    nato ally tuesday welcome...</td>\n",
       "      <td>brussel  reuter    nato alli tuesday welcom pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>london  reuters    lexisnexis  provider legal ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>london  reuters    lexisnexis  provider legal ...</td>\n",
       "      <td>london  reuter    lexisnexi  provid legal  reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>minsk  reuters    shadow disused soviet era fa...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>minsk  reuters    shadow disused soviet era fa...</td>\n",
       "      <td>minsk  reuter    shadow disus soviet era facto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>moscow  reuters    vatican secretary state car...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>moscow  reuters    vatican secretary state car...</td>\n",
       "      <td>moscow  reuter    vatican secretari state card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>jakarta  reuters    indonesia buy    sukhoi fi...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>jakarta  reuters    indonesia buy    sukhoi fi...</td>\n",
       "      <td>jakarta  reuter    indonesia buy    sukhoi fig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "44893  'Fully committed' NATO backs new U.S. approach...   \n",
       "44894  LexisNexis withdrew two products from Chinese ...   \n",
       "44895  Minsk cultural hub becomes haven from authorities   \n",
       "44896  Vatican upbeat on possibility of Pope Francis ...   \n",
       "44897  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "0      donald trump wish americans happy new year lea...       News   \n",
       "1      house intelligence committee chairman devin nu...       News   \n",
       "2      friday  revealed former milwaukee sheriff davi...       News   \n",
       "3      christmas day  donald trump announced would  b...       News   \n",
       "4      pope francis used annual christmas day message...       News   \n",
       "...                                                  ...        ...   \n",
       "44893  brussels  reuters    nato allies tuesday welco...  worldnews   \n",
       "44894  london  reuters    lexisnexis  provider legal ...  worldnews   \n",
       "44895  minsk  reuters    shadow disused soviet era fa...  worldnews   \n",
       "44896  moscow  reuters    vatican secretary state car...  worldnews   \n",
       "44897  jakarta  reuters    indonesia buy    sukhoi fi...  worldnews   \n",
       "\n",
       "                    date  newstype  \\\n",
       "0      December 31, 2017         0   \n",
       "1      December 31, 2017         0   \n",
       "2      December 30, 2017         0   \n",
       "3      December 29, 2017         0   \n",
       "4      December 25, 2017         0   \n",
       "...                  ...       ...   \n",
       "44893   August 22, 2017          1   \n",
       "44894   August 22, 2017          1   \n",
       "44895   August 22, 2017          1   \n",
       "44896   August 22, 2017          1   \n",
       "44897   August 22, 2017          1   \n",
       "\n",
       "                                                    lemm  \\\n",
       "0      donald trump wish american happy new year leav...   \n",
       "1      house intelligence committee chairman devin nu...   \n",
       "2      friday  revealed former milwaukee sheriff davi...   \n",
       "3      christmas day  donald trump announced would  b...   \n",
       "4      pope francis used annual christmas day message...   \n",
       "...                                                  ...   \n",
       "44893  brussels  reuters    nato ally tuesday welcome...   \n",
       "44894  london  reuters    lexisnexis  provider legal ...   \n",
       "44895  minsk  reuters    shadow disused soviet era fa...   \n",
       "44896  moscow  reuters    vatican secretary state car...   \n",
       "44897  jakarta  reuters    indonesia buy    sukhoi fi...   \n",
       "\n",
       "                                                    stem  \n",
       "0      donald trump wish american happi new year leav...  \n",
       "1      hous intellig committe chairman devin nune go ...  \n",
       "2      friday  reveal former milwauke sheriff david c...  \n",
       "3      christma day  donald trump announc would  back...  \n",
       "4      pope franci use annual christma day messag reb...  \n",
       "...                                                  ...  \n",
       "44893  brussel  reuter    nato alli tuesday welcom pr...  \n",
       "44894  london  reuter    lexisnexi  provid legal  reg...  \n",
       "44895  minsk  reuter    shadow disus soviet era facto...  \n",
       "44896  moscow  reuter    vatican secretari state card...  \n",
       "44897  jakarta  reuter    indonesia buy    sukhoi fig...  \n",
       "\n",
       "[44898 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "result = pd.read_csv('editeddata.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util as cu\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF, bigram, on 'stem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7891610987379362\n",
      "Most Informative Features\n",
      "                  reuter = None             fake : true   =    502.8 : 1.0\n",
      "                  reuter = 0.09578262852211514   true : fake   =     31.4 : 1.0\n",
      "                    said = 0.08606629658238704   true : fake   =     19.7 : 1.0\n",
      "                  presid = 0.07980868844676221   true : fake   =     19.0 : 1.0\n",
      "            donald trump = 0.08137884587711594   true : fake   =     17.7 : 1.0\n",
      "                  donald = 0.08137884587711594   true : fake   =     17.7 : 1.0\n",
      "                  presid = 0.08137884587711594   true : fake   =     16.9 : 1.0\n",
      "                  presid = 0.08481889296799709   true : fake   =     16.9 : 1.0\n",
      "                    said = 0.14784425419091457   true : fake   =     16.8 : 1.0\n",
      "              washington = 0.0842151921066519   true : fake   =     16.3 : 1.0\n",
      "                     say = 0.08084520834544433   true : fake   =     16.2 : 1.0\n",
      "              washington = 0.07692307692307693   true : fake   =     15.6 : 1.0\n",
      "            donald trump = 0.07602859212697055   true : fake   =     15.5 : 1.0\n",
      "                  donald = 0.07602859212697055   true : fake   =     15.5 : 1.0\n",
      "                    said = 0.07881104062391006   true : fake   =     15.4 : 1.0\n",
      "                    said = 0.09578262852211514   true : fake   =     15.4 : 1.0\n",
      "                  reuter = 0.06262242910851495   true : fake   =     14.8 : 1.0\n",
      "                     say = 0.07980868844676221   true : fake   =     14.8 : 1.0\n",
      "                     say = 0.08606629658238704   true : fake   =     14.8 : 1.0\n",
      "                  presid = 0.08192319205190406   true : fake   =     14.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "vcBayesInput = []\n",
    "vec_tfidf_bi = TfidfVectorizer(analyzer = 'word', ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "x=result['stem'].values\n",
    "y=result['newstype'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0,test_size=0.25)\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    word_count = {}\n",
    "    X = vec_tfidf_bi.fit_transform([x_train[i]]).toarray()\n",
    "    features = vec_tfidf_bi.get_feature_names()\n",
    "    for j in range(len(features)):\n",
    "        word_count[features[j]] = X[0][j]\n",
    "    vcBayesInput.append((word_count, \"fake\" if y_train[i] == 0 else \"true\"))\n",
    "    \n",
    "random.seed(12)\n",
    "random.shuffle(vcBayesInput)\n",
    "\n",
    "size = len(vcBayesInput)\n",
    "train_size = int(0.8 * size)\n",
    "train_set, test_set = vcBayesInput[0:train_size], vcBayesInput[train_size:size]\n",
    "\n",
    "model = NaiveBayesClassifier.train(train_set)\n",
    "ac = cu.accuracy(model, test_set)\n",
    "print(ac)\n",
    "model.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer, bigram, on 'stem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795100222717149\n",
      "Most Informative Features\n",
      "             featur imag = 1                fake : true   =   1780.7 : 1.0\n",
      "       washington reuter = 1                true : fake   =   1241.4 : 1.0\n",
      "                    http = 1                fake : true   =    877.8 : 1.0\n",
      "                  reuter = None             fake : true   =    498.1 : 1.0\n",
      "            reuter senat = 1                true : fake   =    249.1 : 1.0\n",
      "              imag video = 1                fake : true   =    213.3 : 1.0\n",
      "                     pic = 2                fake : true   =    211.8 : 1.0\n",
      "           reuter presid = 1                true : fake   =    210.6 : 1.0\n",
      "              screenshot = 1                fake : true   =    173.3 : 1.0\n",
      "            video screen = 1                fake : true   =    166.9 : 1.0\n",
      "             seen reuter = 1                true : fake   =    149.2 : 1.0\n",
      "             citi reuter = 1                true : fake   =    138.9 : 1.0\n",
      "                subscrib = 1                fake : true   =    131.2 : 1.0\n",
      "                      ck = 1                fake : true   =    129.5 : 1.0\n",
      "          reuter russian = 1                true : fake   =    124.4 : 1.0\n",
      "            imag twitter = 1                fake : true   =    122.2 : 1.0\n",
      "           reuter donald = 1                true : fake   =    114.9 : 1.0\n",
      "     independ referendum = 1                true : fake   =    103.9 : 1.0\n",
      "              lower hous = 1                true : fake   =     98.1 : 1.0\n",
      "                    beij = 2                true : fake   =     94.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "vcBayesInput = []\n",
    "vec_tfidf_bi = CountVectorizer(analyzer = 'word', ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "x=result['stem'].values\n",
    "y=result['newstype'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0,test_size=0.25)\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    word_count = {}\n",
    "    X = vec_tfidf_bi.fit_transform([x_train[i]]).toarray()\n",
    "    features = vec_tfidf_bi.get_feature_names()\n",
    "    for j in range(len(features)):\n",
    "        word_count[features[j]] = X[0][j]\n",
    "    vcBayesInput.append((word_count, \"fake\" if y_train[i] == 0 else \"true\"))\n",
    "    \n",
    "random.seed(12)\n",
    "random.shuffle(vcBayesInput)\n",
    "\n",
    "size = len(vcBayesInput)\n",
    "train_size = int(0.8 * size)\n",
    "train_set, test_set = vcBayesInput[0:train_size], vcBayesInput[train_size:size]\n",
    "\n",
    "model = NaiveBayesClassifier.train(train_set)\n",
    "ac = cu.accuracy(model, test_set)\n",
    "print(ac)\n",
    "model.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF, bigram, on 'lemm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8060876020786933\n",
      "Most Informative Features\n",
      "                 reuters = None             fake : true   =    502.7 : 1.0\n",
      "                   video = 0.22941573387056174   fake : true   =     34.7 : 1.0\n",
      "                 reuters = 0.09578262852211514   true : fake   =     28.5 : 1.0\n",
      "              washington = 0.07930515857181442   true : fake   =     21.3 : 1.0\n",
      "              washington = 0.08606629658238704   true : fake   =     20.6 : 1.0\n",
      "               president = 0.08362420100070908   true : fake   =     19.8 : 1.0\n",
      "            donald trump = 0.07930515857181442   true : fake   =     19.1 : 1.0\n",
      "                  donald = 0.07930515857181442   true : fake   =     19.1 : 1.0\n",
      "               president = 0.08873565094161139   true : fake   =     19.0 : 1.0\n",
      "              washington = 0.07647191129018725   true : fake   =     18.4 : 1.0\n",
      "                   trump = 0.22941573387056174   fake : true   =     17.7 : 1.0\n",
      "                 reuters = 0.07053456158585983   true : fake   =     17.7 : 1.0\n",
      "            donald trump = 0.08247860988423225   true : fake   =     17.7 : 1.0\n",
      "                  donald = 0.08247860988423225   true : fake   =     17.7 : 1.0\n",
      "              washington = 0.08084520834544433   true : fake   =     16.3 : 1.0\n",
      "                 reuters = 0.10369516947304253   true : fake   =     16.3 : 1.0\n",
      "            donald trump = 0.07980868844676221   true : fake   =     16.3 : 1.0\n",
      "            donald trump = 0.08873565094161139   true : fake   =     16.3 : 1.0\n",
      "                  donald = 0.07980868844676221   true : fake   =     16.2 : 1.0\n",
      "               president = 0.0854357657716761   true : fake   =     16.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "vcBayesInput = []\n",
    "vec_tfidf_bi = TfidfVectorizer(analyzer = 'word', ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "x=result['lemm'].values\n",
    "y=result['newstype'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0,test_size=0.25)\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    word_count = {}\n",
    "    X = vec_tfidf_bi.fit_transform([x_train[i]]).toarray()\n",
    "    features = vec_tfidf_bi.get_feature_names()\n",
    "    for j in range(len(features)):\n",
    "        word_count[features[j]] = X[0][j]\n",
    "    vcBayesInput.append((word_count, \"fake\" if y_train[i] == 0 else \"true\"))\n",
    "    \n",
    "random.seed(12)\n",
    "random.shuffle(vcBayesInput)\n",
    "\n",
    "size = len(vcBayesInput)\n",
    "train_size = int(0.8 * size)\n",
    "train_set, test_set = vcBayesInput[0:train_size], vcBayesInput[train_size:size]\n",
    "\n",
    "model = NaiveBayesClassifier.train(train_set)\n",
    "ac = cu.accuracy(model, test_set)\n",
    "print(ac)\n",
    "model.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer, bigram, on 'lemm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcBayesInput = []\n",
    "vec_tfidf_bi = CountVectorizer(analyzer = 'word', ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "x=result['lemm'].values\n",
    "y=result['newstype'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0,test_size=0.25)\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    word_count = {}\n",
    "    X = vec_tfidf_bi.fit_transform([x_train[i]]).toarray()\n",
    "    features = vec_tfidf_bi.get_feature_names()\n",
    "    for j in range(len(features)):\n",
    "        word_count[features[j]] = X[0][j]\n",
    "    vcBayesInput.append((word_count, \"fake\" if y_train[i] == 0 else \"true\"))\n",
    "    \n",
    "random.seed(12)\n",
    "random.shuffle(vcBayesInput)\n",
    "\n",
    "size = len(vcBayesInput)\n",
    "train_size = int(0.8 * size)\n",
    "train_set, test_set = vcBayesInput[0:train_size], vcBayesInput[train_size:size]\n",
    "\n",
    "model = NaiveBayesClassifier.train(train_set)\n",
    "ac = cu.accuracy(model, test_set)\n",
    "print(ac)\n",
    "model.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
